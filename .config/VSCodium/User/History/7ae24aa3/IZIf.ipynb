{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy import signal\n",
    "import IPython\n",
    "import warnings\n",
    "from pylab import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edoardo Vassallo\n",
    "### S4965918\n",
    "\n",
    "# Lofi e Serendipità\n",
    "[![Alt text](res/img/lofi-girl-music.gif \"lo-fi girl\")](https://www.youtube.com/watch?v=jfKfPfyJRdk)\n",
    "\n",
    "La serendipità è l'idea di trovare qualcosa involontariamente, o mentre si cerca qualcos'altro. La sottocategoria musicale del lofi è figlia di questa idea. Essa infatti cerca di replicare in registrazioni digitali moderne, alcuni dei difetti delle vecchie registrazioni analogiche su nastro o su disco (_lo-fi_ sta infatti per _low fidelity_). <br>\n",
    "\n",
    "E perchè mai farebbero ciò? Questo è quello che questo notebook intende scoprire, analizzando tre filtri che sono utilizzati per replicare questi difetti, per comprendere i vantaggi artistici che portano alla traccia musicale.\n",
    "\n",
    "## Metodi\n",
    "\n",
    "Il seguente notbook cercherà di replicare i difetti sopracitati attraverso filtri di natura simile. Si mostrerà l'effetto di essi su un suono semplice, od un insieme di suoni semplici, e si mostrerà un esempio su un suono complesso, se ne è stato ritrovato uno. <br>\n",
    "\n",
    "Il codice originale dei filtri mostrati era in codice MATLAB, esso è stato tradotto in codice Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low End Head Bumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low End Head Bump filter, as a peak filter \n",
    "\n",
    "# DA MODIFICARE\n",
    "\n",
    "def peakfilt(x, Wc, Wb, G):\n",
    "    # Applies a peak filter to the input signal x.\n",
    "    # Wc is the normalized center frequency 0<Wc<1, i.e. 2*fc/fS.\n",
    "    # Wb is the normalized bandwidth 0<Wb<1, i.e. 2*fb/fS.\n",
    "    # G is the gain in dB.\n",
    "\n",
    "    V0 = 10**(G/20)\n",
    "    H0 = V0 - 1\n",
    "\n",
    "    if G >= 0:\n",
    "        c = (np.tan(np.pi * Wb / 2) - 1) / (np.tan(np.pi * Wb / 2) + 1)  # boost\n",
    "    else:\n",
    "        c = (np.tan(np.pi * Wb / 2) - V0) / (np.tan(np.pi * Wb / 2) + V0)  # cut\n",
    "\n",
    "    d = -np.cos(np.pi * Wc)\n",
    "    xh = np.array([0, 0])\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "\n",
    "    for n in range(len(x)):\n",
    "        xh_new = x[n] - d * (1 - c) * xh[0] + c * xh[1]\n",
    "        ap_y = -c * xh_new + d * (1 - c) * xh[0] + xh[1]\n",
    "        xh = np.array([xh_new, xh[0]])\n",
    "        y[n] = 0.5 * H0 * (x[n] - ap_y) + x[n]\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tape Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tape Saturation Filters\n",
    "\n",
    "# Arctangent filter\n",
    "def arctan_dist(input, alpha):\n",
    "    # input : input signal\n",
    "    # alpha : distortion amount (1-10)\n",
    "\n",
    "    N = len(input)\n",
    "    out = np.zeros_like(input)\n",
    "\n",
    "    for n in range(N):\n",
    "        out[n] = 2 * np.pi * np.arctan(alpha * input[n]) \n",
    "    return out\n",
    "\n",
    "# Cubic filter\n",
    "def cubic_dist(input, alpha):\n",
    "    # input : input signal\n",
    "    # alpha : distortion amount (0-1), \n",
    "    #         amplitude of 3rd harmonic\n",
    "\n",
    "    N = len(input)\n",
    "    out = np.zeros(N)\n",
    "\n",
    "    for n in range(N):\n",
    "        out[n] = input[n] - alpha * (1/3) * input[n]**3\n",
    "\n",
    "    return out\n",
    "\n",
    "# Exponential filter\n",
    "\n",
    "# Piece-Wise filter\n",
    "\n",
    "# Parallel Distortion filter\n",
    "\n",
    "# Overdrive filter, with softclipping, page 125\n",
    "def symclip(x):\n",
    "    # \"Overdrive\" simulation with symmetrical clipping\n",
    "    # x - input\n",
    "    N = len(x)\n",
    "    th = 1/3  # threshold for symmetrical soft clipping by Schetzen Formula\n",
    "    y = np.zeros(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        if abs(x[i]) < th:\n",
    "            y[i] = 2 * x[i]\n",
    "\n",
    "        if abs(x[i]) >= th:\n",
    "            if x[i] > 0:\n",
    "                y[i] = (3 - (2 - x[i] * 3)**2) / 3\n",
    "            if x[i] < 0:\n",
    "                y[i] = -(3 - (2 - abs(x[i]) * 3)**2) / 3\n",
    "\n",
    "        if abs(x[i]) > 2 * th:\n",
    "            if x[i] > 0:\n",
    "                y[i] = 1\n",
    "            if x[i] < 0:\n",
    "                y[i] = -1\n",
    "\n",
    "    return y\n",
    "\n",
    "# Distorsion filter, page 127\n",
    "def exp_dist(x, gain, mix):\n",
    "    # Distortion based on an exponential function\n",
    "    # x - input\n",
    "    # gain - amount of distortion, >0\n",
    "    # mix - mix of original and distorted sound, 1=only distorted\n",
    "    q = x * gain\n",
    "    z = np.sign(q) * (1 - np.exp(-np.abs(q)))\n",
    "    y = mix * z + (1 - mix) * x\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow and Flutters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wows and Flutter Filter, as a vibrato filter\n",
    "\n",
    "def vibrato(x, SAMPLERATE, Modfreq, Width):\n",
    "    ya_alt = 0\n",
    "    Delay = Width  # basic delay of input sample in sec\n",
    "    DELAY = round(Delay * SAMPLERATE)  # basic delay in # samples\n",
    "    WIDTH = round(Width * SAMPLERATE)  # modulation width in # samples\n",
    "\n",
    "    if WIDTH > DELAY:\n",
    "        raise ValueError('Delay greater than basic delay !!!')\n",
    "\n",
    "    MODFREQ = Modfreq / SAMPLERATE  # modulation frequency in # samples\n",
    "    LEN = len(x)  # # of samples in WAV-file\n",
    "    L = 2 + DELAY + WIDTH * 2  # length of the entire delay\n",
    "    Delayline = np.zeros(L)  # memory allocation for delay\n",
    "    y = np.zeros_like(x)  # memory allocation for output vector\n",
    "\n",
    "    for n in range(LEN - 1):\n",
    "        M = MODFREQ\n",
    "        MOD = np.sin(M * 2 * np.pi * n)\n",
    "        TAP = 1 + DELAY + WIDTH * MOD\n",
    "        i = int(np.floor(TAP))\n",
    "        frac = TAP - i\n",
    "        Delayline = np.concatenate(([x[n]], Delayline[:L-1]))\n",
    "\n",
    "        # Linear Interpolation\n",
    "        y[n] = Delayline[i + 1] * frac + Delayline[i] * (1 - frac)\n",
    "\n",
    "        # Allpass Interpolation\n",
    "        # Effetto più forte\n",
    "        # y[n] = (Delayline[i + 1] + (1 - frac) * Delayline[i] - (1 - frac) * ya_alt)\n",
    "        # ya_alt = y[n]\n",
    "\n",
    "        # Spline Interpolation \n",
    "        # Effetto più leggero\n",
    "        # y[n] = (Delayline[i + 1] * frac**3 / 6\n",
    "        #         + Delayline[i] * ((1 + frac)**3 - 4 * frac**3) / 6\n",
    "        #         + Delayline[i - 1] * ((2 - frac)**3 - 4 * (1 - frac)**3) / 6\n",
    "        #         + Delayline[i - 2] * (1 - frac)**3 / 6)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonti\n",
    "\n",
    "#### DA FINIRE\n",
    "\n",
    "### Bibliografia\n",
    "1. [_DAFX: Digital Audio Effects, Second Edition._](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119991298) <br>\n",
    "    Edited by Udo Zölzer. © 2011 John Wiley & Sons, Ltd. <br>\n",
    "    Published 2011 by John Wiley & Sons, Ltd. <br>\n",
    "    ISBN: 978-0-470-66599-2\n",
    "\n",
    "2. [_Analogue Tape Simulation in MATLAB_](https://ses.library.usyd.edu.au/bitstream/handle/2123/22615/DESC9115%20-%20Analogue%20Tape%20Simulation%20in%20MATLAB%20-%20Written%20Report.pdf?sequence=1&isAllowed=y) <br>\n",
    "    Digital Audio Systems, DESC9115, 2020 <br>\n",
    "    Master of Architectural Science (Audio and Acoustics) <br>\n",
    "    Sydney School of Architecture, Design and Planning, The University of Sydney\n",
    "\n",
    "### Sitografia\n",
    "\n",
    "1. [_The Unpredictable Joys of Analog Recording_](https://www.endino.com/graphs/) <br>\n",
    "    Jack Endino (2000-2006), www.endino.com\n",
    "2. [_Explained: The Famous Lo-Fi Effect (And How To Make It)_](https://www.productionmusiclive.com/blogs/news/lofi-effect-explained) <br>\n",
    "    Pelle Sundin, www.productionmusiclive.com\n",
    "3. [_Tape Saturation - what is it and how do you use it_](https://samplecraze.com/tutorials/tape-saturation-what-is-it-and-how-do-you-use-it/) <br>\n",
    "    www.samplecraze.com\n",
    "### Video\n",
    "\n",
    "1. [_Tape Saturation Explained_](https://www.youtube.com/watch?v=Fx9PY7AZL7M)<br>\n",
    "    Short and Sweet Tutorials, Youtube\n",
    "2. [_\"What do wow and flutter sound like?\"_](https://youtu.be/kCwRdrFtJuE?si=tqJqsC1hfC1dbH_U) <br>\n",
    "    M. Zillch, Youtube"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
